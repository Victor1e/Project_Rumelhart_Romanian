{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhtO+kjH4FonDvE2XHtjZO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Victor1e/Project_Rumelhart_Romanian/blob/main/varianta_veche.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UYDyp0XutEIW",
        "outputId": "cf18315f-a0ed-452c-95a3-2f0659e191e5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)             â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ•°ï¸ Antrenam modelul VECHI (Retro)...\n",
            "Epoch 1/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.6252 - loss: 1.7279 - val_accuracy: 0.8438 - val_loss: 0.6373\n",
            "Epoch 2/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8407 - loss: 0.5724 - val_accuracy: 0.9370 - val_loss: 0.3084\n",
            "Epoch 3/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9340 - loss: 0.2681 - val_accuracy: 0.9864 - val_loss: 0.1105\n",
            "Epoch 4/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9820 - loss: 0.1029 - val_accuracy: 0.9939 - val_loss: 0.0424\n",
            "Epoch 5/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9921 - loss: 0.0466 - val_accuracy: 0.9981 - val_loss: 0.0210\n",
            "Epoch 6/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9964 - loss: 0.0246 - val_accuracy: 0.9995 - val_loss: 0.0099\n",
            "Epoch 7/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9984 - loss: 0.0155 - val_accuracy: 1.0000 - val_loss: 0.0055\n",
            "Epoch 8/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9991 - loss: 0.0099 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
            "Epoch 9/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9996 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
            "Epoch 10/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9996 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 11/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9996 - loss: 0.0044 - val_accuracy: 0.9998 - val_loss: 0.0014\n",
            "Epoch 12/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9995 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9997 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 8.3501e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9998 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 6.6484e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9997 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 5.3277e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9999 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 4.6551e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 3.9247e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 3.7626e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 3.0186e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9999 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 2.5421e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 2.2322e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 2.1874e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 1.7754e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 8.4087e-04 - val_accuracy: 1.0000 - val_loss: 1.7447e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 1.4349e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.6391e-04 - val_accuracy: 1.0000 - val_loss: 1.4787e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 7.8643e-04 - val_accuracy: 1.0000 - val_loss: 1.1353e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 7.9963e-04 - val_accuracy: 1.0000 - val_loss: 1.1103e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9999 - loss: 6.8776e-04 - val_accuracy: 1.0000 - val_loss: 1.1183e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9999 - loss: 7.2225e-04 - val_accuracy: 1.0000 - val_loss: 9.4768e-05\n",
            "Epoch 31/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 5.4027e-04 - val_accuracy: 1.0000 - val_loss: 7.5724e-05\n",
            "Epoch 32/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 4.9062e-04 - val_accuracy: 1.0000 - val_loss: 7.2322e-05\n",
            "Epoch 33/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9999 - loss: 6.6822e-04 - val_accuracy: 1.0000 - val_loss: 7.6285e-05\n",
            "Epoch 34/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 6.1257e-04 - val_accuracy: 1.0000 - val_loss: 6.9926e-05\n",
            "Epoch 35/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.5318e-04 - val_accuracy: 1.0000 - val_loss: 6.9205e-05\n",
            "Epoch 36/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 4.8931e-04 - val_accuracy: 1.0000 - val_loss: 5.3943e-05\n",
            "Epoch 37/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9999 - loss: 4.8461e-04 - val_accuracy: 1.0000 - val_loss: 5.8718e-05\n",
            "Epoch 38/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 3.2948e-04 - val_accuracy: 1.0000 - val_loss: 4.6145e-05\n",
            "Epoch 39/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 3.3173e-04 - val_accuracy: 1.0000 - val_loss: 4.0508e-05\n",
            "Epoch 40/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9999 - loss: 3.8433e-04 - val_accuracy: 1.0000 - val_loss: 3.8211e-05\n",
            "Epoch 41/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 4.4805e-04 - val_accuracy: 1.0000 - val_loss: 3.8209e-05\n",
            "Epoch 42/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 3.8365e-04 - val_accuracy: 1.0000 - val_loss: 3.4051e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 3.7714e-04 - val_accuracy: 1.0000 - val_loss: 3.5858e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.4080e-04 - val_accuracy: 1.0000 - val_loss: 2.7942e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.8622e-04 - val_accuracy: 1.0000 - val_loss: 2.6099e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.2227e-04 - val_accuracy: 1.0000 - val_loss: 3.5581e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.5568e-04 - val_accuracy: 1.0000 - val_loss: 3.5136e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.5419e-04 - val_accuracy: 1.0000 - val_loss: 2.8788e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.5280e-04 - val_accuracy: 1.0000 - val_loss: 3.2700e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.9127e-04 - val_accuracy: 1.0000 - val_loss: 3.4074e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 3.6202e-04 - val_accuracy: 1.0000 - val_loss: 2.3929e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.7159e-04 - val_accuracy: 1.0000 - val_loss: 2.4487e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.7565e-04 - val_accuracy: 1.0000 - val_loss: 6.1349e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.4065e-04 - val_accuracy: 1.0000 - val_loss: 2.4017e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.1822e-04 - val_accuracy: 1.0000 - val_loss: 2.9602e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 3.2272e-04 - val_accuracy: 1.0000 - val_loss: 2.5012e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.8724e-04 - val_accuracy: 1.0000 - val_loss: 2.0877e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.8752e-04 - val_accuracy: 1.0000 - val_loss: 3.6460e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.6831e-04 - val_accuracy: 1.0000 - val_loss: 2.6347e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9999 - loss: 3.2093e-04 - val_accuracy: 1.0000 - val_loss: 2.3866e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.2775e-04 - val_accuracy: 1.0000 - val_loss: 1.3449e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.5461e-04 - val_accuracy: 1.0000 - val_loss: 1.0827e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.1705e-04 - val_accuracy: 1.0000 - val_loss: 1.3586e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.4585e-04 - val_accuracy: 1.0000 - val_loss: 1.0376e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.3908e-04 - val_accuracy: 1.0000 - val_loss: 1.3404e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.5060e-04 - val_accuracy: 1.0000 - val_loss: 9.1690e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.2925e-04 - val_accuracy: 1.0000 - val_loss: 1.2290e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.2747e-04 - val_accuracy: 1.0000 - val_loss: 9.3987e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.2045e-04 - val_accuracy: 1.0000 - val_loss: 1.1588e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.0292e-04 - val_accuracy: 1.0000 - val_loss: 9.4612e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.2841e-04 - val_accuracy: 1.0000 - val_loss: 8.0887e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.0018e-04 - val_accuracy: 1.0000 - val_loss: 8.6359e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.3819e-05 - val_accuracy: 1.0000 - val_loss: 7.8516e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 9.7858e-05 - val_accuracy: 1.0000 - val_loss: 8.2979e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.2458e-04 - val_accuracy: 1.0000 - val_loss: 7.5990e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.3928e-04 - val_accuracy: 1.0000 - val_loss: 1.0239e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 8.8002e-05 - val_accuracy: 1.0000 - val_loss: 7.1512e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.1040e-04 - val_accuracy: 1.0000 - val_loss: 3.8253e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 9.2273e-05 - val_accuracy: 1.0000 - val_loss: 8.6794e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 9.3704e-05 - val_accuracy: 1.0000 - val_loss: 4.9920e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 8.2206e-05 - val_accuracy: 1.0000 - val_loss: 5.4078e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 8.2752e-05 - val_accuracy: 1.0000 - val_loss: 5.1535e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9998 - loss: 2.8037e-04 - val_accuracy: 1.0000 - val_loss: 1.5790e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9999 - loss: 5.3205e-04 - val_accuracy: 1.0000 - val_loss: 2.6435e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9999 - loss: 3.0750e-04 - val_accuracy: 1.0000 - val_loss: 1.1434e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.7232e-04 - val_accuracy: 1.0000 - val_loss: 1.6989e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.7860e-04 - val_accuracy: 1.0000 - val_loss: 3.0391e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9999 - loss: 2.2009e-04 - val_accuracy: 1.0000 - val_loss: 4.9599e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.9826e-04 - val_accuracy: 1.0000 - val_loss: 5.1738e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.0829e-04 - val_accuracy: 1.0000 - val_loss: 4.8699e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.1148e-04 - val_accuracy: 1.0000 - val_loss: 4.3751e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.3094e-04 - val_accuracy: 1.0000 - val_loss: 6.7264e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.1792e-05 - val_accuracy: 1.0000 - val_loss: 4.6372e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 7.6588e-05 - val_accuracy: 1.0000 - val_loss: 5.7173e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9999 - loss: 3.6916e-04 - val_accuracy: 1.0000 - val_loss: 9.6637e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9999 - loss: 3.2097e-04 - val_accuracy: 1.0000 - val_loss: 5.8689e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.0526e-04 - val_accuracy: 1.0000 - val_loss: 2.1058e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9999 - loss: 3.3520e-04 - val_accuracy: 1.0000 - val_loss: 6.1898e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.3972e-04 - val_accuracy: 1.0000 - val_loss: 2.2755e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.3410e-04 - val_accuracy: 1.0000 - val_loss: 4.9048e-05\n",
            "\n",
            "REZULTATE MODEL VECHI\n",
            "Infinitiv: manca        -> Prezicere: mancat\n",
            "Infinitiv: fi           -> Prezicere: fost\n",
            "Infinitiv: scrie        -> Prezicere: scris\n",
            "Infinitiv: boganiza     -> Prezicere: boganit\n",
            "Infinitiv: programiza   -> Prezicere: pucerat\n",
            "Infinitiv: cauta        -> Prezicere: cautat\n",
            "Infinitiv: vedea        -> Prezicere: vazut\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten, Reshape, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "\n",
        "# ==========================================\n",
        "# 1. GENERARE DATE (Aceeasi ca la varianta Pro)\n",
        "# ==========================================\n",
        "def genereaza_verbe_regulate(n=1000):\n",
        "    consoane = list(\"bcdfghjklmnprstvz\")\n",
        "    vocale = list(\"aeiou\")\n",
        "    verbe = []\n",
        "    for _ in range(n):\n",
        "        lungime = random.randint(3, 5)\n",
        "        radacina = \"\"\n",
        "        for i in range(lungime):\n",
        "            if i % 2 == 0: radacina += random.choice(consoane)\n",
        "            else: radacina += random.choice(vocale)\n",
        "\n",
        "        if random.random() > 0.3:\n",
        "            infinitiv = radacina + \"a\"\n",
        "            trecut = radacina + \"at\"\n",
        "        else:\n",
        "            infinitiv = radacina + \"i\"\n",
        "            trecut = radacina + \"it\"\n",
        "        verbe.append((infinitiv, trecut))\n",
        "    return verbe\n",
        "\n",
        "verbe_reale = [\n",
        "    (\"fi\", \"fost\"), (\"avea\", \"avut\"), (\"bea\", \"baut\"), (\"da\", \"dat\"),\n",
        "    (\"sta\", \"stat\"), (\"lua\", \"luat\"), (\"vedea\", \"vazut\"), (\"vrea\", \"vrut\"),\n",
        "    (\"stii\", \"stiut\"), (\"veni\", \"venit\"), (\"scrie\", \"scris\"), (\"spune\", \"spus\"),\n",
        "    (\"face\", \"facut\"), (\"zice\", \"zis\"), (\"duce\", \"dus\"), (\"rupe\", \"rupt\"),\n",
        "    (\"coace\", \"copt\"), (\"fierbe\", \"fiert\"), (\"aduce\", \"adus\"),\n",
        "    (\"manca\", \"mancat\"), (\"pleca\", \"plecat\"), (\"cauta\", \"cautat\")\n",
        "]\n",
        "\n",
        "# Folosim acelasi dataset ca sa fie comparatia corecta\n",
        "dataset = genereaza_verbe_regulate(3000) + verbe_reale * 50\n",
        "random.shuffle(dataset)\n",
        "\n",
        "# ==========================================\n",
        "# 2. PREPROCESARE\n",
        "# ==========================================\n",
        "all_text = \"\".join([x[0] + x[1] for x in dataset])\n",
        "chars = sorted(list(set(all_text)))\n",
        "char_to_int = {c: i+2 for i, c in enumerate(chars)}\n",
        "char_to_int['<PAD>'] = 0\n",
        "char_to_int['<UNK>'] = 1\n",
        "int_to_char = {i: c for c, i in char_to_int.items()}\n",
        "vocab_size = len(char_to_int)\n",
        "max_len = 16\n",
        "\n",
        "def encode_word(word):\n",
        "    return [char_to_int.get(c, 1) for c in word]\n",
        "\n",
        "X = pad_sequences([encode_word(p[0]) for p in dataset], maxlen=max_len, padding='post')\n",
        "Y = pad_sequences([encode_word(p[1]) for p in dataset], maxlen=max_len, padding='post')\n",
        "Y_onehot = to_categorical(Y, num_classes=vocab_size)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y_onehot, test_size=0.1, random_state=42)\n",
        "\n",
        "# ==========================================\n",
        "# 3. ARHITECTURA \"RETRO\" (1986 Style - MLP)\n",
        "# ==========================================\n",
        "model_retro = Sequential()\n",
        "\n",
        "# Embedding (Pastram reprezentarea literelor)\n",
        "model_retro.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_len))\n",
        "\n",
        "# --- DIFERENTA MAJORA AICI ---\n",
        "# Aplatizam totul. Reteaua nu mai vede secventa (stanga-dreapta),\n",
        "# ci vede o lista lunga de numere amestecate.\n",
        "# E ca si cum ai incerca sa citesti o fraza vazand toate literele deodata, nu pe rand.\n",
        "model_retro.add(Flatten())\n",
        "\n",
        "# Hidden Layer (Pattern Associator)\n",
        "# O retea densa clasica (Feed Forward)\n",
        "model_retro.add(Dense(512, activation='relu'))\n",
        "model_retro.add(Dropout(0.3))\n",
        "\n",
        "# Output Layer\n",
        "# Trebuie sa scoata tot cuvantul deodata\n",
        "model_retro.add(Dense(max_len * vocab_size, activation='softmax'))\n",
        "# Il rearanjam in forma de cuvant (Litere x Vocabular)\n",
        "model_retro.add(Reshape((max_len, vocab_size)))\n",
        "\n",
        "model_retro.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_retro.summary()\n",
        "\n",
        "# ==========================================\n",
        "# 4. ANTRENARE\n",
        "# ==========================================\n",
        "print(\"\\nğŸ•°ï¸ Antrenam modelul VECHI (Retro)...\")\n",
        "history = model_retro.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.1,\n",
        "                    verbose=1)\n",
        "\n",
        "# ==========================================\n",
        "# 5. TESTARE COMPARATIVA\n",
        "# ==========================================\n",
        "def predict_retro(word):\n",
        "    vec = pad_sequences([encode_word(word)], maxlen=max_len, padding='post')\n",
        "    pred = model_retro.predict(vec, verbose=0)\n",
        "    res = \"\"\n",
        "    for i in range(max_len):\n",
        "        idx = np.argmax(pred[0][i])\n",
        "        if idx > 1:\n",
        "            res += int_to_char[idx]\n",
        "    return res\n",
        "\n",
        "print(\"\\nREZULTATE MODEL VECHI\")\n",
        "teste = [\"manca\", \"fi\", \"scrie\", \"boganiza\", \"programiza\", \"cauta\", \"vedea\"]\n",
        "\n",
        "for t in teste:\n",
        "    res = predict_retro(t)\n",
        "    print(f\"Infinitiv: {t:12} -> Prezicere: {res}\")"
      ]
    }
  ]
}